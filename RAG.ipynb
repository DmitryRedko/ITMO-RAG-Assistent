{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e4175efd17049e282269a2088b9d60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce71919363244c099f8a32c44dbe94ea",
              "IPY_MODEL_aea6dafbd22243e2baeb6884ea1cc6f9",
              "IPY_MODEL_f043ba9aa9c648588decb4dac0033ffb"
            ],
            "layout": "IPY_MODEL_4accb402e98248e99177e77f7f54e462"
          }
        },
        "ce71919363244c099f8a32c44dbe94ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d722ecbbc5da49609e99ff1347e0ca2b",
            "placeholder": "​",
            "style": "IPY_MODEL_e71fd89f906c44ebb76f389cd6eb9355",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "aea6dafbd22243e2baeb6884ea1cc6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd3f63273184ab78e650fbb28e2776e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3991544bfc744919df3280adf329329",
            "value": 2
          }
        },
        "f043ba9aa9c648588decb4dac0033ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a22c6d610544dadb986731c48526c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_75cfcaeef7aa4678b446b53cfad9fc2e",
            "value": " 2/2 [01:14&lt;00:00, 34.24s/it]"
          }
        },
        "4accb402e98248e99177e77f7f54e462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d722ecbbc5da49609e99ff1347e0ca2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71fd89f906c44ebb76f389cd6eb9355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd3f63273184ab78e650fbb28e2776e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3991544bfc744919df3280adf329329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a22c6d610544dadb986731c48526c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75cfcaeef7aa4678b446b53cfad9fc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка необходимых модулей"
      ],
      "metadata": {
        "id": "p-XlzndbQtJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hPoALtgnJAh",
        "outputId": "da54bc6c-d637-4422-da38-32355b2c5031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git@15641892985b1d77acc74c9065c332cd7c3f7d7f\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 15641892985b1d77acc74c9065c332cd7c3f7d7f) to /tmp/pip-req-build-jg1nq_jp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-jg1nq_jp\n",
            "  Running command git rev-parse -q --verify 'sha^15641892985b1d77acc74c9065c332cd7c3f7d7f'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 15641892985b1d77acc74c9065c332cd7c3f7d7f\n",
            "  Running command git checkout -q 15641892985b1d77acc74c9065c332cd7c3f7d7f\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 15641892985b1d77acc74c9065c332cd7c3f7d7f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-hw7md7yo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-hw7md7yo\n",
            "  Resolved https://github.com/huggingface/peft.git to commit f5a95930c23f8fbfc887f157a9ca456765d5577c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0.dev0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: transformers, peft\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6892926 sha256=5520421e79d7f9c2feae650362501983152d00275a228601958351686dec9324\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/6e/a2/8626e266b2b29762ef0cb6903ae366b9efab0a3c1236941a7a\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.8.2-py3-none-any.whl size=183985 sha256=c35a36cb8b3e21f4f8ad24d80eb30019d8dcf4bf915fb1a0a31914506584c3fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lrmkmkss/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "Successfully built transformers peft\n",
            "Installing collected packages: tokenizers, bitsandbytes, transformers, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed accelerate-0.27.2 bitsandbytes-0.42.0 peft-0.8.2 tokenizers-0.13.3 transformers-4.28.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch sentencepiece \\\n",
        "  accelerate \\\n",
        "  bitsandbytes \\\n",
        "  git+https://github.com/huggingface/transformers.git@15641892985b1d77acc74c9065c332cd7c3f7d7f \\\n",
        "  git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKeDqHu3mRSv",
        "outputId": "0c71d3d3-0550-4662-8e8f-c03066bac6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0.dev0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.0.dev0\n",
            "    Uninstalling transformers-4.28.0.dev0:\n",
            "      Successfully uninstalled transformers-4.28.0.dev0\n",
            "Successfully installed tokenizers-0.15.2 transformers-4.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инициализация модели"
      ],
      "metadata": {
        "id": "VTJ-DQsPQ0HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "\n",
        "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
        "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
        "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\"\n",
        "\n",
        "class Conversation:\n",
        "    def __init__(\n",
        "        self,\n",
        "        message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
        "        system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
        "        response_template=DEFAULT_RESPONSE_TEMPLATE\n",
        "    ):\n",
        "        self.message_template = message_template\n",
        "        self.response_template = response_template\n",
        "        self.messages = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt\n",
        "        }]\n",
        "\n",
        "    def add_user_message(self, message):\n",
        "        self.messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": message\n",
        "        })\n",
        "\n",
        "    def add_bot_message(self, message):\n",
        "        self.messages.append({\n",
        "            \"role\": \"bot\",\n",
        "            \"content\": message\n",
        "        })\n",
        "\n",
        "    def get_prompt(self, tokenizer):\n",
        "        final_text = \"\"\n",
        "        for message in self.messages:\n",
        "            message_text = self.message_template.format(**message)\n",
        "            final_text += message_text\n",
        "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
        "        return final_text.strip()\n",
        "\n",
        "\n",
        "def generate(model, tokenizer, prompt, generation_config):\n",
        "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "    data = {k: v.to(model.device) for k, v in data.items()}\n",
        "    output_ids = model.generate(\n",
        "        **data,\n",
        "        generation_config=generation_config\n",
        "    )[0]\n",
        "    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n",
        "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "    return output.strip()\n",
        "\n",
        "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "print(generation_config)\n"
      ],
      "metadata": {
        "id": "u9K_tRxGnNRo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "1e4175efd17049e282269a2088b9d60f",
            "ce71919363244c099f8a32c44dbe94ea",
            "aea6dafbd22243e2baeb6884ea1cc6f9",
            "f043ba9aa9c648588decb4dac0033ffb",
            "4accb402e98248e99177e77f7f54e462",
            "d722ecbbc5da49609e99ff1347e0ca2b",
            "e71fd89f906c44ebb76f389cd6eb9355",
            "cdd3f63273184ab78e650fbb28e2776e",
            "f3991544bfc744919df3280adf329329",
            "6a22c6d610544dadb986731c48526c8b",
            "75cfcaeef7aa4678b446b53cfad9fc2e"
          ]
        },
        "outputId": "f905ba2c-6433-4802-cabe-7154c8dd5a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e4175efd17049e282269a2088b9d60f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_new_tokens\": 1536,\n",
            "  \"no_repeat_ngram_size\": 15,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.2,\n",
            "  \"top_k\": 40,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка базы знаний"
      ],
      "metadata": {
        "id": "1gzUCaNGQ41V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/vacancies.pt'\n",
        "data = torch.load(filename)"
      ],
      "metadata": {
        "id": "M6dDlMaT4wDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever\n",
        "\n"
      ],
      "metadata": {
        "id": "CKwweQe6Q71p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer as BT\n",
        "from transformers import BertModel as BM\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from tqdm import tqdm\n",
        "\n",
        "bert_tokenizer = BT.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model = BM.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "keywords = ['python', 'excel', 'php' 'go', 'golang', 'java', 'swift', 'kotlin', 'angular', 'javascript', 'html', 'css', 'sql', 'mongodb', 'postgresql', 'tensorflow', 'pytorch', 'keras', 'pandas', 'numpy', 'django', 'flask', 'spring', 'react', 'vue', 'angularjs', 'typescript', 'android', 'ios', 'docker', 'kubernetes', 'aws', 'azure', 'gcp', 'git', 'jenkins', 'ansible', 'terraform', 'devops', 'agile', 'scrum', 'machine learning', 'deep learning', 'data science', 'big data', 'cloud computing']\n",
        "\n",
        "def check_keywords(description,keywords):\n",
        "    for keyword in keywords:\n",
        "        if keyword in description.lower():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = bert_tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def get_similar(data,name,max_sim,words_to_find,user_embedding):\n",
        "    escription_embedding = data[name]\n",
        "    similarity = torch.cosine_similarity(user_embedding, escription_embedding, dim=1).item()\n",
        "\n",
        "    flag = 1\n",
        "    if(len(words_to_find) > 0):\n",
        "        flag = check_keywords(data['Описание'], words_to_find)\n",
        "\n",
        "\n",
        "    if(data['Сходство'] >= max_sim):\n",
        "        data['Сходство'] = similarity*flag\n",
        "        max_sim = data['Сходство']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z1zcSUa95DUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd2b839-de3b-4b0c-acbb-f46cfc891b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_job_by_index(data, index):\n",
        "    for job in data:\n",
        "        if job['Index'] == index:\n",
        "            return [str(job['Название вакансии']),str(job['Компания']),[str(job['Описание'])]]"
      ],
      "metadata": {
        "id": "I5G3-sxbh1Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_jobs(user_experience):\n",
        "  user_embedding = get_bert_embeddings(user_experience)\n",
        "\n",
        "\n",
        "  user_promt_splited = user_experience.replace(',', '').split()\n",
        "  words_to_find = []\n",
        "  for x in user_promt_splited:\n",
        "      if(x in keywords):\n",
        "          words_to_find+=[x]\n",
        "\n",
        "  k = 0\n",
        "  for job in tqdm(data):\n",
        "      job['Сходство'] = 0\n",
        "      max_sim = 0\n",
        "      get_similar(job,'Embeded',max_sim,words_to_find,user_embedding)\n",
        "\n",
        "\n",
        "  sorted_jobs = sorted(data, key=lambda x: x['Сходство'], reverse=True)\n",
        "  return sorted_jobs"
      ],
      "metadata": {
        "id": "RRb9RFmgh5L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Использование"
      ],
      "metadata": {
        "id": "F92B5S3wRqb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Без базы знаний"
      ],
      "metadata": {
        "id": "mC1p78pAQeUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_experience = \"Подскажи несколько вакансий для Python разработчика и требования к кандидатам\".lower()\n",
        "\n",
        "conversation = Conversation()\n",
        "\n",
        "question = f\"\\nuser:{user_experience}\\nbot: Вот ответ на ваш вопрос длиной не более 100 слов:\"\n",
        "conversation.add_user_message(question)\n",
        "prompt = conversation.get_prompt(tokenizer)\n",
        "output = generate(model, tokenizer, prompt, generation_config)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "j3Deb219gJtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00326219-2538-4455-daca-887725df29ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вакансии для Python-разработчиков могут включать в себя различные роли, такие как веб-разработчик, машинное обучение, бэкенд-разработчик, фронтенд-разработчик и т.д.\n",
            "\n",
            "Требования к кандидатам зависят от конкретного проекта или компании, но общими являются знание языка программирования Python, базовых алгоритмов и структур данных, работы с базами данных, опыт работы с API и библиотеками Python, а также умение работать в команде.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## С базой знаний"
      ],
      "metadata": {
        "id": "XQJFLuFCQgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = Conversation()\n",
        "\n",
        "sorted_jobs = get_similar_jobs(user_experience)\n",
        "output = \"\"\n",
        "question = f\"\"\"promt: {get_job_by_index(data,sorted_jobs[0]['Index'])}, {get_job_by_index(data,sorted_jobs[1]['Index'])}, {get_job_by_index(data,sorted_jobs[2]['Index'])}\n",
        "               \\nuser:{user_experience}\n",
        "               \\nbot: Вот ответ на ваш вопрос длиной не более 100 слов:\"\"\"\n",
        "conversation.add_user_message(question)\n",
        "prompt = conversation.get_prompt(tokenizer)\n",
        "output = generate(model, tokenizer, prompt, generation_config)\n",
        "print(\"\\n\\nДанные из базы знаний:\\n\")\n",
        "for vacancy in [get_job_by_index(data,sorted_jobs[0]['Index']),get_job_by_index(data,sorted_jobs[1]['Index']),get_job_by_index(data,sorted_jobs[2]['Index'])]:\n",
        "  for x in vacancy:\n",
        "    print(x)\n",
        "  print()\n",
        "print(\"========================LLM SAIGA===========================\")\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "DMYLx1KXC1tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b275443b-6ce7-4b16-e549-6ae296e0e537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 476/476 [00:00<00:00, 17686.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Данные из базы знаний:\n",
            "\n",
            "QA automation\n",
            "RAIDIX, Санкт-Петербург\n",
            "['Условия: Полный рабочий день,опыт работы от 1 до 1 лет,высшее образование,з/п обсуждается на собеседовании руб. Требования к кандидату: Высшее/неоконченное высшее техническое образование;\\r Опыт программирования на Python;\\r Знакомство с Linux.\\r Плюсом будет:\\r Понимание теории тестирования ПО\\r Опыт работы в команде с применением средств коллективной разработки (JIRA, GitLab, Docker);\\r Опыт настройки CI/CD в Gitlab\\r Опыт администрирования Linux.\\r Знание фреймворка тестирования PyTest. Обязанности: Разработка и поддержка текущего тестового фреймворка;\\r Автоматизация тестовых сценариев (PyTest, TestRail);\\r Разработка новых сервисов для взаимодействия с ручными тестировщиками и разработчиками ПО;\\r Встраивание автотестов в CI/CD;\\r Настройка тестовых полигонов;']\n",
            "\n",
            "Junior Software Engineer\n",
            "Big Data Solutions, Санкт-Петербург\n",
            "['Условия: Полный рабочий день,опыт работы от 1 до 1 лет,высшее образование,з/п по результатам собеседования руб. Требования к кандидату: - Отличное знание Python 3.\\r - Знание базовых алгоритмов и структур данных. Умение оценивать пространственную и временную сложность.\\r - Разговорный и письменный английский (это обязательно, у нас международная команда и клиенты).\\r - Уверенная работа с Linux. Обязанности: Наши продукты активно развиваются, поэтому у нас много задач по разработке нового функционала. Это подразумевает несколько этапов разработки: проектирование архитектуры, написание кода, покрытие тестами, ревью, деплой и тестирование на UAT(User Acceptance Testing) сервере и после этого деплой на production сервер. \\r Все сложные и ресурсоемкие модули продуктов написаны на Onetick. Они оркестрируются с помощью специального pipeline, написанного на Python. В работе применяются современные архитектурные решения, такие как AWS, CICD и прочее. \\r Onetick - times-series база данных и язык запросов к ней. Запросы на OneTick можно представить как направленные ациклические графы, где каждый узел - это операция над данными. Такие запросы создаются в графическом редакторе или с помощью высокоуровневого pandas-like API на языке Python. \\r Стек технологий: Python 3, AWS, Docker, Linux, Git (GitLab), Onetick. \\r Процессы: Scrum, Agile, 2х недельные спринты.']\n",
            "\n",
            "Full-Stack разработчик/ Junior разработчик\n",
            "Проект Biletarium, Санкт-Петербург\n",
            "['Условия: Полный рабочий день,опыт работы от 1 до 5 лет,высшее образование,з/п Обсуждается индивидуально руб. Требования к кандидату: Мы ищем человека, а может и сразу несколько под проект в команду in house. Того, кто постоянно развивается, изучает новые технологии, готов работать не в большой корпорации, а в молодом старт-апе с большими возможностями по реализации собственных идей, но и с не меньшей ответственностью за результат.\\r Технологии, знание части из которых уже точно подходит для того, чтобы стать частью нашей команды: Python, Django, JS (ES6+), Node.js, Vue + Nuxt.js, MongoDB, HTML, CSS и адаптивная верстка. Мы используем Docker и Git. Опыт работы с Flutter будет вашим преимуществом Обязанности: Задача – интегрировать проекты с внешними билетными системами, сторонними сервисами, настраивать эквайринги и дорабатывать текущий функционал проектов. У нас уже есть люди, которые этим занимаются, но их силы не безграничны. Мы хотим усилить их команду. После интеграций потребуется поддержка уже существующего кода и разработка новой функциональности, включая добавление новых модулей системы.']\n",
            "\n",
            "========================LLM SAIGA===========================\n",
            "Вот несколько вакансий для Python разработчиков:\n",
            "\n",
            "1. Вакансия \"Python разработчик\" в компании \"РАИДИКС\". Требуется опыт работы от 1 года, высшее образование, знание фреймворка тестирования PyTest.\n",
            "\n",
            "2. Вакансия \"Junior Software Engineer\" в компании \"Big Data Solutions\". Требуется опыт работы от 1 года и знание Python 3.\n",
            "\n",
            "3. Вакансия \"Full-Stack разработчик/ Junior разработчиk\" в проекте \"Biletarium\". Требуется опыт работы от 1 до 5 лет и знание технологий, таких как Python, Django, JS, Node.js, Vue + Nuxt.js, MongoDb, HTML, CSS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_experience = \"Какие еще компетенции нужны для этой работы? Отобрази в виде списка стек для Python разработчика\".lower()\n",
        "question = f\"\"\"promt: {output}\n",
        "               \\nuser:{user_experience}\n",
        "               \\nbot: Вот ответ на ваш вопрос длиной не более 100 слов:\"\"\"\n",
        "\n",
        "conversation.add_user_message(question)\n",
        "prompt = conversation.get_prompt(tokenizer)\n",
        "output = generate(model, tokenizer, prompt, generation_config)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdigAiF6fvwX",
        "outputId": "b7d62865-c389-4633-ffca-f8dafae541e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вакансия \"Python разработчик\" в компании RAIDIX требует знаний в области теории тестирования ПО, опыта работы в команде с применением средств коллективного разработки (JIRA, GitLab, Docker), опыта настройки CI/CD в Gitlab, опыта администрирования Linux, знания фреймворка тестирования PyTest.\n",
            "\n",
            "Вакансия \"Junior Software Engineer\" в компании Big Data Solutions требует знания базовых алгоритмов и структур данных, умения оценивать пространственную и временную сложноть, уверенной работы с Linux, знания Python 3.\n",
            "\n",
            "Вакансия \"Full-Stack разработчик/ Junior разрабoтчик\" в проекте Biletarium требует знания технологий, таких как Python, Django, JS (ES6+), Node.js (Vue + Nuxt.js), MongoDB, HTML, CSS и адаптивная верставка. Также желательно знание Flutter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_experience = \"Какие компетенции нужны для этой работы? Какие soft скилы нужно подтянуть?\".lower()\n",
        "question = f\"\"\"promt: {output}\n",
        "               \\nuser:{user_experience}\n",
        "               \\nbot: Вот ответ на ваш вопрос длиной не более 100 слов:\"\"\"\n",
        "\n",
        "conversation.add_user_message(question)\n",
        "prompt = conversation.get_prompt(tokenizer)\n",
        "output = generate(model, tokenizer, prompt, generation_config)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9w84l1lgrgU",
        "outputId": "e5bf0274-2b47-42e2-99d2-e310c1324f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Для работы в качестве Python разработчика важно иметь следующие компетенции:\n",
            "\n",
            "1. Знание языка программирования Python.\n",
            "2. Знание базовых алгоритмов и структура данных.\n",
            "3. Умение оценивать пространственную и времявую сложность.\n",
            "4. Уверенная работа с Linux.\n",
            "5. Знание фреймворка тестирования PyTest (для вакансии RAIDIX).\n",
            "6. Опыт работы в команде с применением средств CODE (JIRA, GitLab, Docker) (для вакансии RAIDIX).\n",
            "7. Опыт настройки CI/CD в Gitlab (для вакансии RAIDIX).\n",
            "8. Опыт администрирования Linux (для вакансии RAIDIX).\n",
            "9. Знание фреймворка тестирования Pytest (для вакансии RAIDIX).\n",
            "10. Опыт работы в команде с применением средства CODE (JIRA, GitLab, Docker) и опыт настройки CI/CD в Gitlab (dля вакансии Big Data Solutions).\n",
            " bot: Для работы в качестве Python разработчика важен также набор soft skills, такой как:\n",
            "\n",
            "1. Коммуникабельность.\n",
            "2. Организованность.\n",
            "3. Способность работать в команде.\n",
            "4. Способность самостоятельно обучаться и развиваться.\n",
            "5. Критический мышление.\n",
            "6. Способность находить решения проблем.\n",
            "7. Способность работать под давлением.\n",
            "8. Способность работать с различными типами пользователей.\n",
            "9. Способность работать с различными технологиями.\n",
            "10. Способность работать в рамках бюджета и сроков.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJgy8GkXZK8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}